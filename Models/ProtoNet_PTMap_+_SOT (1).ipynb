{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "pakODrOSa55f",
        "wnAZ9fhXfLDt",
        "_u4mRNQYh7uU"
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        " # **Challenge 1**"
      ],
      "metadata": {
        "id": "3Y1_ukbiqmWK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "bXtvKJ7vU7Fc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define datasets and loaders"
      ],
      "metadata": {
        "id": "B3n0Ll_RU144"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries\n",
        "!pip install requests tqdm pillow\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "import tarfile\n",
        "from PIL import Image\n",
        "import shutil  # Importing shutil here\n",
        "\n",
        "import os.path as osp\n",
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "import torch\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zj6CJZqe0SuB",
        "outputId": "37899a35-f204-44d4-fd9f-882467198185"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (9.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def download_file(url, filename):\n",
        "    \"\"\"\n",
        "    Helper method handling downloading large files from `url` to `filename`. Returns a pointer to `filename`.\n",
        "    \"\"\"\n",
        "    chunkSize = 1024\n",
        "    r = requests.get(url, stream=True)\n",
        "    with open(filename, 'wb') as f:\n",
        "        pbar = tqdm(unit=\"B\", total=int(r.headers['Content-Length']))\n",
        "        for chunk in r.iter_content(chunk_size=chunkSize):\n",
        "            if chunk:  # filter out keep-alive new chunks\n",
        "                pbar.update(len(chunk))\n",
        "                f.write(chunk)\n",
        "    return filename\n",
        "\n",
        "if not os.path.exists(\"cifar-10-python.tar.gz\"):\n",
        "    print(\"Downloading cifar-10-python.tar.gz\\n\")\n",
        "    download_file('https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz', 'cifar-10-python.tar.gz')\n",
        "    print(\"Downloading done.\\n\")\n",
        "else:\n",
        "    print(\"Dataset already downloaded. Did not download twice.\\n\")\n",
        "\n",
        "# Unpack the tar file\n",
        "tarname = \"cifar-10-python.tar.gz\"\n",
        "print(\"Untarring: {}\".format(tarname))\n",
        "tar = tarfile.open(tarname)\n",
        "tar.extractall()\n",
        "tar.close()\n",
        "\n",
        "datapath = \"cifar-10-batches-py\"\n",
        "\n",
        "print(\"Extracting jpg images and classes from pickle files\")\n",
        "# in CIFAR 10, the files are given in multiple batch files for training\n",
        "batches = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'test_batch']\n",
        "labels = pickle.load(open(os.path.join(datapath, 'batches.meta'), 'rb'), encoding=\"ASCII\")\n",
        "\n",
        "# Create directories for train, val, and test\n",
        "os.makedirs(os.path.join('cifar-fs', 'train'), exist_ok=True)\n",
        "os.makedirs(os.path.join('cifar-fs', 'val'), exist_ok=True)\n",
        "os.makedirs(os.path.join('cifar-fs', 'test'), exist_ok=True)\n",
        "\n",
        "for i, batch in enumerate(batches):\n",
        "    print(\"Handling pickle file: {}\".format(batch))\n",
        "    fpath = os.path.join(datapath, batch)\n",
        "    with open(fpath, 'rb') as f:\n",
        "        d = pickle.load(f, encoding='bytes')\n",
        "    for j, (img, label) in enumerate(zip(d[b'data'], d[b'labels'])):\n",
        "        img = img.reshape(3, 32, 32).transpose(1, 2, 0)  # Convert from CHW to HWC\n",
        "        img_folder = labels['label_names'][label]\n",
        "        dataset_type = 'test' if i == len(batches) - 1 else 'train'  # Last batch is test set\n",
        "        if i < len(batches) - 1 and j < 1000:  # First 1000 images of train set used as val\n",
        "            dataset_type = 'val'\n",
        "        img_path = os.path.join('cifar-fs', dataset_type, img_folder)\n",
        "        os.makedirs(img_path, exist_ok=True)\n",
        "        img_filename = os.path.join(img_path, f'{j}.jpg')\n",
        "        Image.fromarray(img).save(img_filename)\n",
        "\n",
        "print(\"Cleaning up downloaded files\")\n",
        "os.remove('cifar-10-python.tar.gz')\n",
        "shutil.rmtree(datapath, ignore_errors=True)\n",
        "print(\"Setup complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT_CibWR0Nph",
        "outputId": "462c0da0-d249-4e77-aa82-c69623a99c8b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cifar-10-python.tar.gz\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 31868428.22B/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading done.\n",
            "\n",
            "Untarring: cifar-10-python.tar.gz\n",
            "Extracting jpg images and classes from pickle files\n",
            "Handling pickle file: data_batch_1\n",
            "Handling pickle file: data_batch_2\n",
            "Handling pickle file: data_batch_3\n",
            "Handling pickle file: data_batch_4\n",
            "Handling pickle file: data_batch_5\n",
            "Handling pickle file: test_batch\n",
            "Cleaning up downloaded files\n",
            "Setup complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CategoriesSampler:\n",
        "\n",
        "    def __init__(self, set_name, labels, num_episodes,\n",
        "                 num_way, num_shot, num_query, const_loader, replace=True):\n",
        "\n",
        "        self.set_name = set_name\n",
        "        self.num_way = num_way\n",
        "        self.num_shot = num_shot\n",
        "        self.num_query = num_query\n",
        "        self.num_episodes = num_episodes\n",
        "        self.const_loader = const_loader   # same tasks in different epochs. good for validation\n",
        "        self.replace = replace             # sample few-shot tasks with replacement (same class can appear twice or more\n",
        "\n",
        "        self.m_ind = []\n",
        "        self.batches = []\n",
        "\n",
        "        labels = np.array(labels)\n",
        "        for i in range(max(labels) + 1):\n",
        "            ind = np.argwhere(labels == i).reshape(-1)\n",
        "            ind = torch.from_numpy(ind)\n",
        "            self.m_ind.append(ind)\n",
        "\n",
        "        self.classes = np.arange(len(self.m_ind))\n",
        "\n",
        "        if self.const_loader:\n",
        "            for i_batch in range(self.num_episodes):\n",
        "                batch = []\n",
        "                # -- faster loading with np.choice -- #\n",
        "                # classes = torch.randperm(len(self.m_ind))[:self.num_way]\n",
        "                classes = np.random.choice(self.classes, size=self.num_way, replace=self.replace)\n",
        "                for c in classes:\n",
        "                    l = self.m_ind[c]\n",
        "                    pos = np.random.choice(np.arange(l.shape[0]),\n",
        "                                           size=self.num_shot + self.num_query,\n",
        "                                           replace=False)\n",
        "                    batch.append(l[pos])\n",
        "\n",
        "                batch = torch.from_numpy(np.stack(batch)).t().reshape(-1)\n",
        "                self.batches.append(batch)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.num_episodes\n",
        "\n",
        "    def __iter__(self):\n",
        "        if not self.const_loader:\n",
        "            for batch_idx in range(self.num_episodes):\n",
        "                batch = []\n",
        "                # classes = torch.randperm(len(self.m_ind))[:self.num_way]\n",
        "                classes = np.random.choice(self.classes, size=self.num_way, replace=self.replace)\n",
        "                for c in classes:\n",
        "                    l = self.m_ind[c]\n",
        "                    pos = np.random.choice(np.arange(l.shape[0]),\n",
        "                                           size=self.num_shot + self.num_query,\n",
        "                                           replace=False)\n",
        "                    batch.append(l[pos])\n",
        "\n",
        "                batch = torch.from_numpy(np.stack(batch)).t().reshape(-1)\n",
        "                yield batch\n",
        "        else:\n",
        "            for batch_idx in range(self.num_episodes):\n",
        "                yield self.batches[batch_idx]\n",
        "\n",
        "\n",
        "\n",
        "class CIFAR(Dataset):\n",
        "\n",
        "    def __init__(self, data_path: str, setname: str, backbone: str, augment: bool):\n",
        "        d = osp.join(data_path, setname)\n",
        "        dirs = [os.path.join(d, o) for o in os.listdir(d) if os.path.isdir(os.path.join(d, o))]\n",
        "\n",
        "        data = []\n",
        "        label = []\n",
        "        lb = -1\n",
        "\n",
        "        for d in dirs:\n",
        "            lb += 1\n",
        "            for image_name in os.listdir(d):\n",
        "                path = osp.join(d, image_name)\n",
        "                data.append(path)\n",
        "                label.append(lb)\n",
        "\n",
        "        self.data = data\n",
        "        self.label = label\n",
        "\n",
        "        mean = [x / 255.0 for x in [129.37731888, 124.10583864, 112.47758569]]\n",
        "        std = [x / 255.0 for x in [68.20947949, 65.43124043, 70.45866994]]\n",
        "        normalize = transforms.Normalize(mean=mean, std=std)\n",
        "\n",
        "        self.image_size = 32\n",
        "        if augment and setname == 'train':\n",
        "            transforms_list = [\n",
        "                transforms.RandomResizedCrop(self.image_size),\n",
        "                transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "        else:\n",
        "            transforms_list = [\n",
        "                transforms.Resize((self.image_size, self.image_size)),\n",
        "                transforms.ToTensor(),\n",
        "            ]\n",
        "\n",
        "        self.transform = transforms.Compose(\n",
        "            transforms_list + [normalize]\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        path, label = self.data[i], self.label[i]\n",
        "        image = self.transform(Image.open(path).convert('RGB'))\n",
        "        return image, label, path\n",
        "\n",
        "\n",
        "def get_transform(img_size: int, split_name: str):\n",
        "    mean = [x / 255.0 for x in [129.37731888, 124.10583864, 112.47758569]]\n",
        "    std = [x / 255.0 for x in [68.20947949, 65.43124043, 70.45866994]]\n",
        "    normalize = transforms.Normalize(mean=mean, std=std)\n",
        "\n",
        "    if split_name == 'train':\n",
        "        return transforms.Compose([\n",
        "            # transforms.RandomResizedCrop((img_size, img_size), scale=(0.05, 1.0)),\n",
        "            transforms.RandomCrop(32, padding=4),\n",
        "            transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4),\n",
        "            transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])\n",
        "\n",
        "    else:\n",
        "        return transforms.Compose([\n",
        "            transforms.Resize((img_size, img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            normalize\n",
        "        ])"
      ],
      "metadata": {
        "id": "OV6EbpwWthSn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = dict(cifar=CIFAR)\n",
        "\n",
        "def get_dataloader(set_name: str\n",
        "                   , num_episodes\n",
        "                   , train_way\n",
        "                   , val_way\n",
        "                   , num_shot\n",
        "                   , num_query\n",
        "                   , data_path\n",
        "                   ,dataset: str = \"cifar\"\n",
        "                   , backbone = 'resnet12'\n",
        "                  , constant: bool = False\n",
        "                   ,augment: bool = False):\n",
        "    \"\"\"\n",
        "    Get dataloader with categorical sampler for few-shot classification.\n",
        "    \"\"\"\n",
        "    # num_episodes = args.set_episodes[set_name]\n",
        "    num_episodes = num_episodes\n",
        "    num_way = train_way if set_name == 'train' else val_way\n",
        "\n",
        "    # define dataset sampler and data loader\n",
        "    data_set = datasets[dataset.lower()](\n",
        "        data_path, set_name, backbone, augment=set_name == 'train' and augment\n",
        "    )\n",
        "    # args.img_size = data_set.image_size\n",
        "\n",
        "    data_sampler = CategoriesSampler(\n",
        "        set_name, data_set.label, num_episodes, const_loader=constant,\n",
        "        num_way=num_way, num_shot=num_shot, num_query=num_query\n",
        "    )\n",
        "    return DataLoader(\n",
        "        data_set, batch_sampler=data_sampler, pin_memory=not constant\n",
        "    )"
      ],
      "metadata": {
        "id": "LY-jytixtTNb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = '/content/cifar-fs'\n",
        "\n",
        "train_loader = get_dataloader(set_name='train'\n",
        "                              , num_episodes=1\n",
        "                              , train_way = 2\n",
        "                              , val_way = 2\n",
        "                              , num_shot = 5\n",
        "                              , num_query =20\n",
        "                              , data_path = dataset_path\n",
        "                              ,dataset = \"cifar\"\n",
        "                              , backbone = 'resnet12'\n",
        "                              , constant = False\n",
        "                              ,augment = False)\n",
        "\n",
        "val_loader = get_dataloader(set_name='val'\n",
        "                              , num_episodes=8\n",
        "                              , train_way = 2\n",
        "                              , val_way = 2\n",
        "                              , num_shot = 5\n",
        "                              , num_query =20\n",
        "                              , data_path = dataset_path\n",
        "                              , dataset = \"cifar\"\n",
        "                              , backbone = 'resnet12'\n",
        "                              , constant = True\n",
        "                              ,augment = False)\n"
      ],
      "metadata": {
        "id": "SrmOOoIOtS48"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# define model"
      ],
      "metadata": {
        "id": "pakODrOSa55f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.distributions import Bernoulli"
      ],
      "metadata": {
        "id": "OdVCYLxFeOZu"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DropBlock(nn.Module):\n",
        "    def __init__(self, block_size):\n",
        "        super(DropBlock, self).__init__()\n",
        "\n",
        "        self.block_size = block_size\n",
        "\n",
        "    def forward(self, x, gamma):\n",
        "        # shape: (bsize, channels, height, width)\n",
        "\n",
        "        if self.training:\n",
        "            batch_size, channels, height, width = x.shape\n",
        "            bernoulli = Bernoulli(gamma)\n",
        "            mask = bernoulli.sample((batch_size, channels, height - (self.block_size - 1), width - (self.block_size - 1)))\n",
        "            if torch.cuda.is_available():\n",
        "                mask = mask.cuda()\n",
        "            block_mask = self._compute_block_mask(mask)\n",
        "            countM = block_mask.size()[0] * block_mask.size()[1] * block_mask.size()[2] * block_mask.size()[3]\n",
        "            count_ones = block_mask.sum()\n",
        "\n",
        "            return block_mask * x * (countM / count_ones)\n",
        "        else:\n",
        "            return x\n",
        "\n",
        "    def _compute_block_mask(self, mask):\n",
        "        left_padding = int((self.block_size-1) / 2)\n",
        "        right_padding = int(self.block_size / 2)\n",
        "\n",
        "        batch_size, channels, height, width = mask.shape\n",
        "        non_zero_idxs = mask.nonzero()\n",
        "        nr_blocks = non_zero_idxs.shape[0]\n",
        "\n",
        "        offsets = torch.stack(\n",
        "            [\n",
        "                torch.arange(self.block_size).view(-1, 1).expand(self.block_size, self.block_size).reshape(-1), # - left_padding,\n",
        "                torch.arange(self.block_size).repeat(self.block_size), #- left_padding\n",
        "            ]\n",
        "        ).t()\n",
        "        offsets = torch.cat((torch.zeros(self.block_size**2, 2).long(), offsets.long()), 1)\n",
        "        if torch.cuda.is_available():\n",
        "            offsets = offsets.cuda()\n",
        "\n",
        "        if nr_blocks > 0:\n",
        "            non_zero_idxs = non_zero_idxs.repeat(self.block_size ** 2, 1)\n",
        "            offsets = offsets.repeat(nr_blocks, 1).view(-1, 4)\n",
        "            offsets = offsets.long()\n",
        "\n",
        "            block_idxs = non_zero_idxs + offsets\n",
        "            #block_idxs += left_padding\n",
        "            padded_mask = F.pad(mask, (left_padding, right_padding, left_padding, right_padding))\n",
        "            padded_mask[block_idxs[:, 0], block_idxs[:, 1], block_idxs[:, 2], block_idxs[:, 3]] = 1.\n",
        "        else:\n",
        "            padded_mask = F.pad(mask, (left_padding, right_padding, left_padding, right_padding))\n",
        "\n",
        "        block_mask = 1 - padded_mask#[:height, :width]\n",
        "        return block_mask\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class ResBasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None, drop_rate=0.0, drop_block=False, block_size=1):\n",
        "        super(ResBasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.LeakyReLU(0.1)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = conv3x3(planes, planes)\n",
        "        self.bn3 = nn.BatchNorm2d(planes)\n",
        "        self.maxpool = nn.MaxPool2d(stride)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "        self.drop_rate = drop_rate\n",
        "        self.num_batches_tracked = 0\n",
        "        self.drop_block = drop_block\n",
        "        self.block_size = block_size\n",
        "        self.DropBlock = DropBlock(block_size=self.block_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        self.num_batches_tracked += 1\n",
        "\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        out = self.maxpool(out)\n",
        "\n",
        "        if self.drop_rate > 0:\n",
        "            if self.drop_block == True:\n",
        "                feat_size = out.size()[2]\n",
        "                keep_rate = max(1.0 - self.drop_rate / (20*2000) * (self.num_batches_tracked), 1.0 - self.drop_rate)\n",
        "                # gamma = (1 - keep_rate) / self.block_size**2 * feat_size**2 / (feat_size - self.block_size + 1)**2\n",
        "                # out = self.DropBlock(out, gamma=gamma)\n",
        "                if (feat_size - self.block_size + 1) > 0:\n",
        "                  gamma = (1 - keep_rate) / self.block_size**2 * feat_size**2 / (feat_size - self.block_size + 1)**2\n",
        "                  out = self.DropBlock(out, gamma=gamma)\n",
        "                else:\n",
        "                    # Skip DropBlock or handle differently\n",
        "                    gamma = 0\n",
        "            else:\n",
        "                out = F.dropout(out, p=self.drop_rate, training=self.training, inplace=True)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "\n",
        "    def __init__(self, block=ResBasicBlock, keep_prob=1.0, avg_pool=True, dropout=0.1, dropblock_size=5):\n",
        "        self.inplanes = 3\n",
        "        drop_rate = dropout\n",
        "        super(ResNet, self).__init__()\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, stride=2, drop_rate=drop_rate)\n",
        "        self.layer2 = self._make_layer(block, 160, stride=2, drop_rate=drop_rate)\n",
        "        self.layer3 = self._make_layer(block, 320, stride=2, drop_rate=drop_rate, drop_block=True, block_size=dropblock_size)\n",
        "        self.layer4 = self._make_layer(block, 640, stride=2, drop_rate=drop_rate, drop_block=True, block_size=dropblock_size)\n",
        "        if avg_pool:\n",
        "            self.avgpool = nn.AvgPool2d(5, stride=1)\n",
        "        self.keep_prob = keep_prob\n",
        "        self.keep_avg_pool = avg_pool\n",
        "        self.dropout = nn.Dropout(p=1 - self.keep_prob, inplace=False)\n",
        "        self.drop_rate = drop_rate\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='leaky_relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, stride=1, drop_rate=0.0, drop_block=False, block_size=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=1, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample, drop_rate, drop_block, block_size))\n",
        "        self.inplanes = planes * block.expansion\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        if self.keep_avg_pool:\n",
        "            x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return x\n",
        "\n",
        "\n",
        "def Res12(keep_prob=1.0, avg_pool=False, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-12 model.\n",
        "    \"\"\"\n",
        "    model = ResNet(ResBasicBlock, keep_prob=keep_prob, avg_pool=avg_pool, **kwargs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "G5mpCt6xaFoc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### dropout has been removed in this code. original code had dropout#####\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import sys, os\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "act = torch.nn.ReLU()\n",
        "\n",
        "import math\n",
        "from torch.nn.utils.weight_norm import WeightNorm\n",
        "\n",
        "\n",
        "class WRNBasicBlock(nn.Module):\n",
        "    def __init__(self, in_planes, out_planes, stride, dropRate=0.0):\n",
        "        super(WRNBasicBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_planes)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_planes)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_planes, out_planes, kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        self.droprate = dropRate\n",
        "        self.equalInOut = (in_planes == out_planes)\n",
        "        self.convShortcut = (not self.equalInOut) and nn.Conv2d(in_planes, out_planes, kernel_size=1, stride=stride,\n",
        "                                                                padding=0, bias=False) or None\n",
        "\n",
        "    def forward(self, x):\n",
        "        if not self.equalInOut:\n",
        "            x = self.relu1(self.bn1(x))\n",
        "        else:\n",
        "            out = self.relu1(self.bn1(x))\n",
        "        out = self.relu2(self.bn2(self.conv1(out if self.equalInOut else x)))\n",
        "        if self.droprate > 0:\n",
        "            out = F.dropout(out, p=self.droprate, training=self.training)\n",
        "        out = self.conv2(out)\n",
        "        return torch.add(x if self.equalInOut else self.convShortcut(x), out)\n",
        "\n",
        "\n",
        "class distLinear(nn.Module):\n",
        "    def __init__(self, indim, outdim):\n",
        "        super(distLinear, self).__init__()\n",
        "        self.L = nn.Linear(indim, outdim, bias=False)\n",
        "        self.class_wise_learnable_norm = True  # See the issue#4&8 in the github\n",
        "        if self.class_wise_learnable_norm:\n",
        "            WeightNorm.apply(self.L, 'weight', dim=0)  # split the weight update component to direction and norm\n",
        "\n",
        "        if outdim <= 200:\n",
        "            self.scale_factor = 2  # a fixed scale factor to scale the output of cos value into a reasonably large input for softmax\n",
        "        else:\n",
        "            self.scale_factor = 10  # in omniglot, a larger scale factor is required to handle >1000 output classes.\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_norm = torch.norm(x, p=2, dim=1).unsqueeze(1).expand_as(x)\n",
        "        x_normalized = x.div(x_norm + 0.00001)\n",
        "        if not self.class_wise_learnable_norm:\n",
        "            L_norm = torch.norm(self.L.weight.data, p=2, dim=1).unsqueeze(1).expand_as(self.L.weight.data)\n",
        "            self.L.weight.data = self.L.weight.data.div(L_norm + 0.00001)\n",
        "        cos_dist = self.L(\n",
        "            x_normalized)  # matrix product by forward function, but when using WeightNorm, this also multiply the cosine distance by a class-wise learnable norm, see the issue#4&8 in the github\n",
        "        scores = self.scale_factor * (cos_dist)\n",
        "\n",
        "        return scores\n",
        "\n",
        "\n",
        "class NetworkBlock(nn.Module):\n",
        "    def __init__(self, nb_layers, in_planes, out_planes, block, stride, dropRate=0.0):\n",
        "        super(NetworkBlock, self).__init__()\n",
        "        self.layer = self._make_layer(block, in_planes, out_planes, nb_layers, stride, dropRate)\n",
        "\n",
        "    def _make_layer(self, block, in_planes, out_planes, nb_layers, stride, dropRate):\n",
        "        layers = []\n",
        "        for i in range(int(nb_layers)):\n",
        "            layers.append(block(i == 0 and in_planes or out_planes, out_planes, i == 0 and stride or 1, dropRate))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layer(x)\n",
        "\n",
        "\n",
        "def to_one_hot(inp, num_classes):\n",
        "    y_onehot = torch.FloatTensor(inp.size(0), num_classes)\n",
        "    if torch.cuda.is_available():\n",
        "        y_onehot = y_onehot.cuda()\n",
        "\n",
        "    y_onehot.zero_()\n",
        "    x = inp.type(torch.LongTensor)\n",
        "    if torch.cuda.is_available():\n",
        "        x = x.cuda()\n",
        "\n",
        "    x = torch.unsqueeze(x, 1)\n",
        "    y_onehot.scatter_(1, x, 1)\n",
        "\n",
        "    return Variable(y_onehot, requires_grad=False)\n",
        "    # return y_onehot\n",
        "\n",
        "\n",
        "def mixup_data(x, y, lam):\n",
        "    '''Compute the mixup data. Return mixed inputs, pairs of targets, and lambda'''\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size)\n",
        "    if torch.cuda.is_available():\n",
        "        index = index.cuda()\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "class WideResNet(nn.Module):\n",
        "    def __init__(self, depth=28, widen_factor=10, num_classes=200, loss_type='dist', per_img_std=False, stride=1,\n",
        "                 dropRate=0.5):\n",
        "        flatten = True\n",
        "        super(WideResNet, self).__init__()\n",
        "        nChannels = [16, 16 * widen_factor, 32 * widen_factor, 64 * widen_factor]\n",
        "        assert ((depth - 4) % 6 == 0)\n",
        "        n = (depth - 4) / 6\n",
        "        block = WRNBasicBlock\n",
        "        # 1st conv before any network block\n",
        "        self.conv1 = nn.Conv2d(3, nChannels[0], kernel_size=3, stride=1,\n",
        "                               padding=1, bias=False)\n",
        "        # 1st block\n",
        "        self.block1 = NetworkBlock(n, nChannels[0], nChannels[1], block, stride, dropRate)\n",
        "        # 2nd block\n",
        "        self.block2 = NetworkBlock(n, nChannels[1], nChannels[2], block, 2, dropRate)\n",
        "        # 3rd block\n",
        "        self.block3 = NetworkBlock(n, nChannels[2], nChannels[3], block, 2, dropRate)\n",
        "        # global average pooling and linear\n",
        "        self.bn1 = nn.BatchNorm2d(nChannels[3])\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.nChannels = nChannels[3]\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        if flatten:\n",
        "            self.final_feat_dim = 640\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x, target=None, mixup=False, mixup_hidden=True, mixup_alpha=None, lam=0.4, return_logits=True):\n",
        "        if target is not None:\n",
        "            if mixup_hidden:\n",
        "                layer_mix = random.randint(0, 3)\n",
        "            elif mixup:\n",
        "                layer_mix = 0\n",
        "            else:\n",
        "                layer_mix = None\n",
        "\n",
        "            out = x\n",
        "\n",
        "            target_a = target_b = target\n",
        "\n",
        "            if layer_mix == 0:\n",
        "                out, target_a, target_b, lam = mixup_data(out, target, lam=lam)\n",
        "\n",
        "            out = self.conv1(out)\n",
        "            out = self.block1(out)\n",
        "\n",
        "            if layer_mix == 1:\n",
        "                out, target_a, target_b, lam = mixup_data(out, target, lam=lam)\n",
        "\n",
        "            out = self.block2(out)\n",
        "\n",
        "            if layer_mix == 2:\n",
        "                out, target_a, target_b, lam = mixup_data(out, target, lam=lam)\n",
        "\n",
        "            out = self.block3(out)\n",
        "            if layer_mix == 3:\n",
        "                out, target_a, target_b, lam = mixup_data(out, target, lam=lam)\n",
        "\n",
        "            out = self.relu(self.bn1(out))\n",
        "            out = F.avg_pool2d(out, out.size()[2:])\n",
        "            out = out.view(out.size(0), -1)\n",
        "            if not return_logits:\n",
        "                return out, target_a, target_b\n",
        "\n",
        "            out1 = self.linear(out)\n",
        "            return out, out1, target_a, target_b\n",
        "        else:\n",
        "            out = x\n",
        "            out = self.conv1(out)\n",
        "            out = self.block1(out)\n",
        "            out = self.block2(out)\n",
        "            out = self.block3(out)\n",
        "            out = self.relu(self.bn1(out))\n",
        "            out = F.avg_pool2d(out, out.size()[2:])\n",
        "            out = out.view(out.size(0), -1)\n",
        "            # if not return_logits:\n",
        "            return out\n",
        "\n",
        "            # out1 = self.linear(out)\n",
        "            # return out, out1\n",
        "\n",
        "\n",
        "def wrn28_10(num_classes=200, loss_type='dist', dropout=0):\n",
        "    model = WideResNet(depth=28, widen_factor=10, num_classes=num_classes, loss_type=loss_type, per_img_std=False,\n",
        "                       stride=1, dropRate=dropout)\n",
        "    return model"
      ],
      "metadata": {
        "id": "ciLrhxRJ4pFL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = dict(wrn=wrn28_10, resnet12=Res12)\n",
        "\n",
        "def get_model(model_name: str, img_size, temperature=0.1, dropout = 0, ):\n",
        "    \"\"\"\n",
        "    Get the backbone model.\n",
        "    \"\"\"\n",
        "    arch = model_name.lower()\n",
        "    if arch in models.keys():\n",
        "        if 'vit' in arch:\n",
        "            model = models[arch](img_size=img_size, patch_size=16)\n",
        "        else:\n",
        "            model = models[arch](dropout=dropout)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "\n",
        "        return model\n",
        "    else:\n",
        "        raise ValueError(f'Model {model_name} not implemented. available models are: {list(models.keys())}')\n"
      ],
      "metadata": {
        "id": "YkJrhEwf4tfP"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " # Self Optimal Transport"
      ],
      "metadata": {
        "id": "wnAZ9fhXfLDt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def log_sum_exp(u: torch.Tensor, dim: int):\n",
        "    # Reduce log sum exp along axis\n",
        "    u_max, __ = u.max(dim=dim, keepdim=True)\n",
        "    log_sum_exp_u = torch.log(torch.exp(u - u_max).sum(dim)) + u_max.sum(dim)\n",
        "    return log_sum_exp_u\n",
        "\n",
        "\n",
        "def log_sinkhorn(M: torch.Tensor, reg: float, num_iters: int):\n",
        "    \"\"\"\n",
        "    Log-space-sinkhorn algorithm for better stability.\n",
        "    \"\"\"\n",
        "    if M.dim() > 2:\n",
        "        return batched_log_sinkhorn(M=M, reg=reg, num_iters=num_iters)\n",
        "\n",
        "    # Initialize dual variable v (u is implicitly defined in the loop)\n",
        "    log_v = torch.zeros(M.size()[1]).to(M.device)  # ==torch.log(torch.ones(m.size()[1]))\n",
        "\n",
        "    # Exponentiate the pairwise distance matrix\n",
        "    log_K = -M / reg\n",
        "\n",
        "    # Main loop\n",
        "    for i in range(num_iters):\n",
        "        # Match r marginals\n",
        "        log_u = - log_sum_exp(log_K + log_v[None, :], dim=1)\n",
        "\n",
        "        # Match c marginals\n",
        "        log_v = - log_sum_exp(log_u[:, None] + log_K, dim=0)\n",
        "\n",
        "    # Compute optimal plan, cost, return everything\n",
        "    log_P = log_u[:, None] + log_K + log_v[None, :]\n",
        "    return log_P\n",
        "\n",
        "\n",
        "def batched_log_sinkhorn(M, reg: float, num_iters: int):\n",
        "    \"\"\"\n",
        "    Batched version of log-space-sinkhorn.\n",
        "    \"\"\"\n",
        "    batch_size, x_points, _ = M.shape\n",
        "    # both marginals are fixed with equal weights\n",
        "    mu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
        "                     requires_grad=False).fill_(1.0 / x_points).squeeze().to(M.device)\n",
        "    nu = torch.empty(batch_size, x_points, dtype=torch.float,\n",
        "                     requires_grad=False).fill_(1.0 / x_points).squeeze().to(M.device)\n",
        "\n",
        "    u = torch.zeros_like(mu)\n",
        "    v = torch.zeros_like(nu)\n",
        "    # To check if algorithm terminates because of threshold\n",
        "    # or max iterations reached\n",
        "    actual_nits = 0\n",
        "    # Stopping criterion\n",
        "    thresh = 1e-1\n",
        "\n",
        "    def C(M, u, v, reg):\n",
        "        \"\"\"Modified cost for logarithmic updates\"\"\"\n",
        "        return (-M + u.unsqueeze(-1) + v.unsqueeze(-2)) / reg\n",
        "\n",
        "    # Sinkhorn iterations\n",
        "    for i in range(num_iters):\n",
        "        u1 = u  # useful to check the update\n",
        "        u = reg * (torch.log(mu + 1e-8) - torch.logsumexp(C(M, u, v, reg), dim=-1)) + u\n",
        "        v = reg * (torch.log(nu + 1e-8) - torch.logsumexp(C(M, u, v, reg).transpose(-2, -1), dim=-1)) + v\n",
        "        err = (u - u1).abs().sum(-1).mean()\n",
        "\n",
        "        actual_nits += 1\n",
        "        if err.item() < thresh:\n",
        "            break\n",
        "\n",
        "    U, V = u, v\n",
        "    # Transport plan pi = diag(a)*K*diag(b)\n",
        "    log_p = C(M, U, V, reg)\n",
        "    return log_p\n",
        "\n",
        "\n",
        "class SOT(object):\n",
        "    supported_distances = ['cosine', 'euclidean']\n",
        "\n",
        "    def __init__(self, distance_metric: str = 'cosine', ot_reg: float = 0.1, sinkhorn_iterations: int = 10,\n",
        "                 sigmoid: bool = False, mask_diag: bool = True, max_scale: bool = True):\n",
        "        \"\"\"\n",
        "        :param distance_metric - Compute the cost matrix.\n",
        "        :param ot_reg - Sinkhorn entropy regularization (lambda). For few-shot classification, 0.1-0.2 works best.\n",
        "        :param sinkhorn_iterations - Maximum number of sinkhorn iterations.\n",
        "        :param sigmoid - If to apply sigmoid(log_p) instead of the usual exp(log_p).\n",
        "        :param mask_diag - Set to true to apply diagonal masking before and after the OT.\n",
        "        :param max_scale - Re-scale the SOT values to range [0,1].\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        assert distance_metric.lower() in SOT.supported_distances and sinkhorn_iterations > 0\n",
        "\n",
        "        self.sinkhorn_iterations = sinkhorn_iterations\n",
        "        self.distance_metric = distance_metric.lower()\n",
        "        self.mask_diag = mask_diag\n",
        "        self.sigmoid = sigmoid\n",
        "        self.ot_reg = ot_reg\n",
        "        self.max_scale = max_scale\n",
        "        self.diagonal_val = 1e3                         # value to mask self-values with\n",
        "\n",
        "    def compute_cost(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute cost matrix.\n",
        "        \"\"\"\n",
        "        if self.distance_metric == 'euclidean':\n",
        "            M = torch.cdist(X, X, p=2)\n",
        "            # scale euclidean distances to [0, 1]\n",
        "            return M / M.max()\n",
        "\n",
        "        elif self.distance_metric == 'cosine':\n",
        "            # cosine distance\n",
        "            return 1 - SOT.cosine_similarity(X)\n",
        "\n",
        "    def mask_diagonal(self, M: torch.Tensor, value: float):\n",
        "        \"\"\"\n",
        "        Set new value at a diagonal matrix.\n",
        "        \"\"\"\n",
        "        if self.mask_diag:\n",
        "            if M.dim() > 2:\n",
        "                M[torch.eye(M.shape[1]).repeat(M.shape[0], 1, 1).bool()] = value\n",
        "            else:\n",
        "                M.fill_diagonal_(value)\n",
        "        return M\n",
        "\n",
        "    def __call__(self, X: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Compute the SOT features for X\n",
        "        \"\"\"\n",
        "        # get masked cost matrix\n",
        "        C = self.compute_cost(X=X)\n",
        "        M = self.mask_diagonal(C, value=self.diagonal_val)\n",
        "\n",
        "        # compute self-OT\n",
        "        z_log = log_sinkhorn(M=M, reg=self.ot_reg, num_iters=self.sinkhorn_iterations)\n",
        "\n",
        "        if self.sigmoid:\n",
        "            z = torch.sigmoid(z_log)\n",
        "        else:\n",
        "            z = torch.exp(z_log)\n",
        "\n",
        "        # divide the SOT matrix by its max to scale it up\n",
        "        if self.max_scale:\n",
        "            z_max = z.max().item() if z.dim() <= 2 else z.amax(dim=(1, 2), keepdim=True)\n",
        "            z = z / z_max\n",
        "\n",
        "        # set self-values to 1\n",
        "        return self.mask_diagonal(z, value=1)\n",
        "\n",
        "    @staticmethod\n",
        "    def cosine_similarity(a: torch.Tensor, eps: float = 1e-8):\n",
        "        \"\"\"\n",
        "        Compute the pairwise cosine similarity between a matrix to itself.\n",
        "        \"\"\"\n",
        "        d_n = a / a.norm(dim=-1, keepdim=True)\n",
        "        if len(a.shape) > 2:\n",
        "            C = torch.bmm(d_n, d_n.transpose(1, 2))\n",
        "        else:\n",
        "            C = torch.mm(d_n, d_n.transpose(0, 1))\n",
        "        return C"
      ],
      "metadata": {
        "id": "md4DF96Re4oW"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Method"
      ],
      "metadata": {
        "id": "_u4mRNQYh7uU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ProtoLoss(nn.Module):\n",
        "    def __init__(self\n",
        "               , train_way\n",
        "               , val_way\n",
        "               , num_shot\n",
        "               , num_query\n",
        "               , temperature = 0.1\n",
        "               , sot: SOT = None):\n",
        "\n",
        "        super().__init__()\n",
        "        self.way_dict = dict(train=train_way, val=val_way)\n",
        "        self.num_shot = num_shot\n",
        "        self.num_query = num_query\n",
        "        self.temperature = temperature\n",
        "        self.SOT = sot  # if sot is None no sot will be applied\n",
        "        self.num_labeled = None\n",
        "\n",
        "    @staticmethod\n",
        "    def get_accuracy(probas: torch.Tensor, labels: torch.Tensor):\n",
        "        y_hat = probas.argmin(dim=-1)\n",
        "        matches = labels.eq(y_hat).float()\n",
        "        m = matches.mean().item()\n",
        "        # pm = matches.std(unbiased=False).item() * 1.96\n",
        "        return m\n",
        "\n",
        "    def forward(self, X: torch.Tensor, labels: torch.Tensor, mode: str):\n",
        "        num_way = self.way_dict[mode]\n",
        "        self.num_labeled = num_way * self.num_shot\n",
        "        if self.SOT is not None:\n",
        "            # compute the SOT matrix\n",
        "            X = self.SOT(X)\n",
        "\n",
        "        X_s, X_q = X[:self.num_labeled], X[self.num_labeled:]\n",
        "        # data is sorted as [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, ...]\n",
        "        # compute centroids\n",
        "        X_c = X_s.reshape(self.num_shot, num_way, -1).transpose(0, 1).mean(dim=1)\n",
        "\n",
        "        # compute distances between queries and the centroids\n",
        "        D = torch.cdist(X_q, X_c) / self.temperature\n",
        "\n",
        "        return -D, ProtoLoss.get_accuracy(D, labels)\n"
      ],
      "metadata": {
        "id": "dybpCH-OaRtl"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\"\"\"\n",
        "Implementation of PT-MAP as a differential module.\n",
        "Original code in https://github.com/yhu01/PT-MAP\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def centerDatas(X: torch.Tensor, n_lsamples: int):\n",
        "    \"\"\"\n",
        "    Center labeled and un-labeled data separately.\n",
        "    \"\"\"\n",
        "    X[:n_lsamples, :] = X[:n_lsamples, :] - X[:n_lsamples, :].mean(0, keepdim=True)\n",
        "    X[n_lsamples:, :] = X[n_lsamples:, :] - X[n_lsamples:, :].mean(0, keepdim=True)\n",
        "    return X\n",
        "\n",
        "\n",
        "# ---------  GaussianModel\n",
        "\n",
        "class GaussianModel:\n",
        "    def __init__(self, num_way: int, num_shot: int, num_query: int, lam: float):\n",
        "        self.num_way = num_way\n",
        "        self.num_shot = num_shot\n",
        "        self.num_query = num_query\n",
        "        self.n_lsamples = num_way * num_shot\n",
        "        self.n_usamples = num_way * num_query\n",
        "        self.lam = lam\n",
        "        self.mus = None  # shape [n_ways][feat_dim]\n",
        "\n",
        "    def cuda(self):\n",
        "        self.mus = self.mus.cuda()\n",
        "\n",
        "    def init_from_labelled(self, X: torch.Tensor):\n",
        "        self.mus = X.reshape(self.num_shot + self.num_query, self.num_way, -1)[:self.num_shot, ].mean(0)\n",
        "\n",
        "    def update_from_estimate(self, estimate, alpha):\n",
        "        Dmus = estimate - self.mus\n",
        "        self.mus = self.mus + alpha * Dmus\n",
        "\n",
        "    def compute_optimal_transport(self, M: torch.Tensor, r: torch.Tensor, c: torch.Tensor, epsilon: float = 1e-6):\n",
        "        n_runs, n, m = M.shape\n",
        "        P = torch.exp(-self.lam * M)\n",
        "        P = P / P.view((n_runs, -1)).sum(1).unsqueeze(1).unsqueeze(1)\n",
        "        u = torch.zeros((n_runs, n), device='cuda')\n",
        "        maxiters = 1000\n",
        "        iters = 1\n",
        "        # normalize this matrix\n",
        "        while torch.max(torch.abs(u - P.sum(-1))) > epsilon:\n",
        "            u = P.sum(dim=-1)\n",
        "            P *= (r / u).view((n_runs, -1, 1))\n",
        "            P *= (c / P.sum(1)).view((n_runs, 1, -1))\n",
        "            if iters == maxiters:\n",
        "                break\n",
        "            iters += 1\n",
        "\n",
        "        if n_runs == 1:\n",
        "            return P.squeeze(0)\n",
        "        return P\n",
        "\n",
        "    def get_probas(self, X: torch.Tensor, labels: torch.Tensor):\n",
        "        dist = torch.cdist(X, self.mus)\n",
        "        p_xj = torch.zeros_like(dist)\n",
        "        r = torch.ones(1, self.num_way * self.num_query, device='cuda')\n",
        "        c = torch.ones(1, self.num_way, device='cuda') * self.num_query\n",
        "        p_xj_test = self.compute_optimal_transport(dist.unsqueeze(0)[:, self.n_lsamples:], r, c, epsilon=1e-6)\n",
        "        p_xj[self.n_lsamples:] = p_xj_test\n",
        "\n",
        "        p_xj[:self.n_lsamples].fill_(0)\n",
        "        p_xj[:self.n_lsamples].scatter_(1, labels[:self.n_lsamples].unsqueeze(1), 1)\n",
        "        return p_xj\n",
        "\n",
        "    def estimate_from_mask(self, X: torch.Tensor, mask: torch.Tensor):\n",
        "        emus = mask.T.matmul(X).div(mask.sum(dim=0).unsqueeze(1))\n",
        "        return emus\n",
        "\n",
        "\n",
        "# =========================================\n",
        "#    MAP\n",
        "# =========================================\n",
        "\n",
        "class MAP:\n",
        "    def __init__(self, labels, alpha: float, num_labeled: int, n_runs=1):\n",
        "        self.alpha = alpha\n",
        "        self.num_labeled = num_labeled\n",
        "        self.s_labels = labels[:self.num_labeled]\n",
        "        self.q_labels = labels[self.num_labeled:]\n",
        "        self.n_runs = n_runs\n",
        "\n",
        "    def get_accuracy(self, probas: torch.Tensor):\n",
        "        y_hat = probas[self.num_labeled:].argmax(dim=-1)\n",
        "        matches = self.q_labels.eq(y_hat).float()\n",
        "        m = matches.mean().item()\n",
        "        pm = matches.std(unbiased=False).item() * 1.96\n",
        "        return m, pm\n",
        "\n",
        "    def perform_epoch(self, model: GaussianModel, X: torch.Tensor):\n",
        "        p_xj = model.get_probas(X=X, labels=self.s_labels)\n",
        "        m_estimates = model.estimate_from_mask(X=X, mask=p_xj)\n",
        "        # update centroids\n",
        "        model.update_from_estimate(m_estimates, self.alpha)\n",
        "\n",
        "    def loop(self, X: torch.Tensor, model: GaussianModel, n_epochs: int = 20):\n",
        "        for epoch in range(1, n_epochs + 1):\n",
        "            self.perform_epoch(model=model, X=X)\n",
        "        # get final accuracy and return it\n",
        "        P = model.get_probas(X=X, labels=self.s_labels)\n",
        "        return P\n",
        "\n",
        "\n",
        "class PTMAPLoss(nn.Module):\n",
        "    def __init__(self\n",
        "                , train_way\n",
        "                , val_way\n",
        "                , num_shot\n",
        "                , num_query\n",
        "                , temperature = 0.1\n",
        "                , lam: float = 10, alpha: float = 0.2, n_epochs: int = 20, sot=None):\n",
        "\n",
        "        super().__init__()\n",
        "        self.way_dict = dict(train=train_way, val=val_way)\n",
        "        self.num_shot = num_shot\n",
        "        self.num_query = num_query\n",
        "        self.lam = lam\n",
        "        self.alpha = alpha\n",
        "        self.n_epochs = n_epochs\n",
        "        self.num_labeled = None\n",
        "        self.SOT = sot  # if sot is None no sot will be applied\n",
        "\n",
        "    def scale(self, X: torch.Tensor, mode: str):\n",
        "        # normalize, center and normalize again\n",
        "        if mode != 'train':\n",
        "            X = F.normalize(X, p=2, dim=-1)\n",
        "            X = centerDatas(X, self.num_labeled)\n",
        "\n",
        "        X = F.normalize(X, p=2, dim=-1)\n",
        "        return X\n",
        "\n",
        "    def forward(self, X: torch.Tensor, labels: torch.Tensor, mode: str):\n",
        "        num_way = self.way_dict[mode]\n",
        "        self.num_labeled = num_way * self.num_shot\n",
        "\n",
        "        # power transform (PT part) and scaling\n",
        "        assert X.min() >= 0, \"Error: To use PT-MAP you need to apply another ReLU on the output features (or use WRN).\"\n",
        "        X = torch.pow(X + 1e-6, 0.5)\n",
        "        Z = self.scale(X=X, mode=mode)\n",
        "\n",
        "        # applying SOT or continue with regular pt-map\n",
        "        if self.SOT is not None:\n",
        "            Z = self.SOT(X=Z)\n",
        "\n",
        "        # MAP\n",
        "        gaussian_model = GaussianModel(num_way=num_way, num_shot=self.num_shot, num_query=self.num_query, lam=self.lam)\n",
        "        gaussian_model.init_from_labelled(X=Z)\n",
        "\n",
        "        optim = MAP(labels=labels, alpha=self.alpha, num_labeled=self.num_labeled)\n",
        "        P = optim.loop(X=Z, model=gaussian_model, n_epochs=self.n_epochs)\n",
        "        accuracy, std = optim.get_accuracy(probas=P)\n",
        "\n",
        "        return torch.log(P[self.num_labeled:] + 1e-5), accuracy"
      ],
      "metadata": {
        "id": "-83NJ3jSaWOa"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "methods = dict(pt_map=PTMAPLoss, pt_map_sot=PTMAPLoss, proto=ProtoLoss, proto_sot=ProtoLoss, )\n",
        "\n",
        "def get_method(method:str\n",
        "               , sot: SOT\n",
        "               , train_way\n",
        "               , val_way\n",
        "               , num_shot\n",
        "               , num_query\n",
        "               , temperature = 0.1\n",
        "               ):\n",
        "    \"\"\"\n",
        "    Get the few-shot classification method (e.g. pt_map).\n",
        "    \"\"\"\n",
        "\n",
        "    if method.lower() in methods.keys():\n",
        "        return methods[method.lower()](\n",
        "                train_way = train_way\n",
        "               , val_way = val_way\n",
        "               , num_shot = num_shot\n",
        "                , num_query = num_query\n",
        "               , temperature = temperature\n",
        "                , sot=sot)\n",
        "    else:\n",
        "        raise ValueError(f'Not implemented method. available methods are: {methods.keys()}')\n"
      ],
      "metadata": {
        "id": "Xe0q4Tfih-kx"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "2zdi2bNEgVH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from time import time\n",
        "try:\n",
        "    import wandb\n",
        "    HAS_WANDB = True\n",
        "except:\n",
        "    HAS_WANDB = False"
      ],
      "metadata": {
        "id": "mOaA852kkedL"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fs_labels(method: str, num_way: int, num_query: int, num_shot: int):\n",
        "    \"\"\"\n",
        "    Prepare few-shot labels. For example for 5-way, 1-shot, 2-query: [0, 1, 2, 3, 4, 0, 1, 2, 3, 4, ...]\n",
        "    \"\"\"\n",
        "    n_samples = num_shot + num_query if 'map' in method else num_query\n",
        "    labels = torch.arange(num_way, dtype=torch.int16).repeat(n_samples).type(torch.LongTensor)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        return labels.cuda()\n",
        "    else:\n",
        "        return labels\n",
        "\n",
        "def log_stepper(results: dict, logger= None):\n",
        "    \"\"\"\n",
        "    Log step to the logger without print.\n",
        "    \"\"\"\n",
        "    if logger is not None:\n",
        "        logger.log(results)\n",
        "\n",
        "    for key, value in results.items():\n",
        "        if 'acc' in key:\n",
        "            print(f\"{key}: {100 * value:.2f}%\")\n",
        "        else:\n",
        "            print(f\"{key}: {value:.4f}\")\n",
        "\n",
        "def print_and_log(results: dict, n: int = 0, logger = None):\n",
        "    \"\"\"\n",
        "    Print and log current results.\n",
        "    \"\"\"\n",
        "    for key in results.keys():\n",
        "        # average by n if needed (n > 0)\n",
        "        if n > 0 and 'time' not in key and '/epoch' not in key:\n",
        "            results[key] = results[key] / n\n",
        "\n",
        "        # print and log\n",
        "        print(f'{key}: {results[key]:.4f}')\n",
        "\n",
        "    if logger is not None:\n",
        "        logger.log(results)\n",
        "\n",
        "\n",
        "def train_one_epoch(model, loader, optimizer, method, criterion, labels, log_step, epoch, device = 'cuda', logger=None):\n",
        "    model.train()\n",
        "    results = {'train/accuracy': 0, 'train/loss': 0}\n",
        "    # start = time.time()\n",
        "    for batch_idx, batch in enumerate(loader):\n",
        "        images = batch[0].to(device)\n",
        "        features = model(images)\n",
        "        # apply few_shot method\n",
        "        probas, accuracy = method(features, labels=labels, mode='train')\n",
        "        q_labels = labels if len(labels) == len(probas) else labels[-len(probas):]\n",
        "\n",
        "        loss = criterion(probas, q_labels)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        results[\"train/loss\"] += loss.item()\n",
        "        results[\"train/accuracy\"] += accuracy\n",
        "\n",
        "        if log_step and (batch_idx + 1) % 50 == 0:\n",
        "            step = batch_idx+((epoch-1) * len(loader))\n",
        "            log_stepper(\n",
        "                results={'train/loss_step': loss.item(), 'train/accuracy_step': accuracy, 'train/train_step': step},\n",
        "                logger=logger\n",
        "            )\n",
        "\n",
        "\n",
        "    # results[\"train/time\"] = time() - start\n",
        "    results[\"train/epoch\"] = epoch\n",
        "    print_and_log(results=results, n=len(loader), logger=logger)\n",
        "    return results\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_one_epoch(model, loader, method, criterion, labels, epoch, logger=None, set_name='val', device = 'cuda'):\n",
        "    model.eval()\n",
        "    results = {f'{set_name}/accuracy': 0, f'{set_name}/loss': 0}\n",
        "\n",
        "    for batch_idx, batch in enumerate(loader):\n",
        "        images = batch[0].to(device)\n",
        "\n",
        "        features = model(images)\n",
        "\n",
        "        # apply few_shot method\n",
        "        probas, accuracy = method(X=features, labels=labels, mode='val')\n",
        "        q_labels = labels if len(labels) == len(probas) else labels[-len(probas):]\n",
        "\n",
        "        loss = criterion(probas, q_labels)\n",
        "\n",
        "        results[f\"{set_name}/loss\"] += loss.item()\n",
        "        results[f\"{set_name}/accuracy\"] += accuracy\n",
        "\n",
        "\n",
        "        if batch_idx % 50 == 0:\n",
        "            step = batch_idx+((epoch-1) * len(loader))\n",
        "            print(f\"Batch {batch_idx + 1}/{len(loader)}: \")\n",
        "            log_stepper(\n",
        "                results={f'{set_name}/loss_step': loss.item(), f'{set_name}/accuracy_step': accuracy,\n",
        "                         f'{set_name}/{set_name}_step': step},\n",
        "                logger=logger\n",
        "            )\n",
        "\n",
        "\n",
        "    results[\"val/epoch\"] = epoch\n",
        "    print_and_log(results=results, n=len(loader), logger=logger)\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "xO-zNVWUihCo"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.0002\n",
        "gamma =  0.5\n",
        "num_way = 2\n",
        "num_query_train = 20\n",
        "num_query_test = 20\n",
        "num_shot = 5\n",
        "device = \"cuda\"\n",
        "\n",
        "model = get_model('resnet12', 32)\n",
        "model.to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40)\n",
        "sot = SOT()\n",
        "method = get_method(\"proto_sot\", sot, num_way, num_way, num_shot, num_query_train)\n",
        "\n",
        " # few-shot labels\n",
        "train_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_train, num_shot=num_shot)\n",
        "val_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_test, num_shot=num_shot)\n",
        "criterion = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "aXbt32hVfULO"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "main loop\n"
      ],
      "metadata": {
        "id": "u-rtdIOkjaE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Start training...\")\n",
        "best_loss = 1000\n",
        "best_acc = 0\n",
        "max_epochs = 20\n",
        "eval_freq = 5\n",
        "\n",
        "for epoch in range(1, max_epochs + 1):\n",
        "    print(f\"Epoch {epoch}/{max_epochs}: \")\n",
        "    # train\n",
        "    train_one_epoch(model, train_loader, optimizer, method, criterion, train_labels, log_step=False , epoch=epoch, device = device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "\n",
        "print('***********************************************************************************')\n",
        "result = eval_one_epoch(model, val_loader, method, criterion, val_labels, epoch = epoch, device = device)\n",
        "print('***********************************************************************************')"
      ],
      "metadata": {
        "id": "_uluOMJEjcIZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4fc3eb3-0b89-419c-a4a8-a03d494f92de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training...\n",
            "Epoch 1/20: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7970\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/20: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5512\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/20: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.7373\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/20: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.4940\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/20: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7236\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/20: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4489\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/20: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.2402\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/20: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.2857\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/20: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 1.4901\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/20: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.9017\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/20: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7213\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/20: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.8911\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/20: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.9108\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/20: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 1.3346\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/20: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6382\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/20: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.9744\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/20: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7547\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/20: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7733\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/20: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 2.2873\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/20: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6035\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.7987\n",
            "val/accuracy_step: 40.00%\n",
            "val/val_step: 152.0000\n",
            "val/accuracy: 0.6156\n",
            "val/loss: 0.7318\n",
            "val/epoch: 20.0000\n",
            "***********************************************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testbed"
      ],
      "metadata": {
        "id": "hoR3Q8ThaHzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet + ProtoNet + SOT"
      ],
      "metadata": {
        "id": "y6zEytULFzmf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "times = []\n",
        "accs = []\n",
        "max_epochs = 100\n",
        "\n",
        "\n",
        "for seed in range(1, 5):\n",
        "  train_loader = get_dataloader(set_name='train'\n",
        "                              , num_episodes=1\n",
        "                              , train_way = 2\n",
        "                              , val_way = 2\n",
        "                              , num_shot = 5\n",
        "                              , num_query =20\n",
        "                              , data_path = dataset_path\n",
        "                              ,dataset = \"cifar\"\n",
        "                              , backbone = 'resnet12'\n",
        "                              , constant = False\n",
        "                              ,augment = False)\n",
        "\n",
        "  val_loader = get_dataloader(set_name='val'\n",
        "                                , num_episodes=8\n",
        "                                , train_way = 2\n",
        "                                , val_way = 2\n",
        "                                , num_shot = 5\n",
        "                                , num_query =20\n",
        "                                , data_path = dataset_path\n",
        "                                , dataset = \"cifar\"\n",
        "                                , backbone = 'resnet12'\n",
        "                                , constant = True\n",
        "                                ,augment = False)\n",
        "\n",
        "  model = get_model('resnet12', 32)\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40)\n",
        "  sot = SOT()\n",
        "  method = get_method(\"proto_sot\", sot, num_way, num_way, num_shot, num_query_train)\n",
        "\n",
        "  # few-shot labels\n",
        "  train_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_train, num_shot=num_shot)\n",
        "  val_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_test, num_shot=num_shot)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(max_epochs):\n",
        "    print(f\"Epoch {epoch}/{max_epochs}: \")\n",
        "    # train\n",
        "    train_one_epoch(model, train_loader, optimizer, method, criterion, train_labels, log_step=False , epoch=epoch, device = device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "  end_time = time.time()\n",
        "  times.append(end_time - start_time)\n",
        "\n",
        "  print('***********************************************************************************')\n",
        "  result = eval_one_epoch(model, val_loader, method, criterion, val_labels, epoch = epoch, device = device)\n",
        "  print('***********************************************************************************')\n",
        "  accs.append(result['val/accuracy'])\n",
        "\n",
        "times = np.array(times)\n",
        "accs = np.array(accs)\n",
        "print('Acc over 5 instances: %.2f +- %.2f'%(accs.mean(),accs.std()))\n",
        "print(f\"Average Time over 5 instances: {times.mean()} +-{times.std()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBoK8LAxPAJ9",
        "outputId": "b64f55f4-c6eb-408c-b3f0-91207b5de22c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.7659\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.3665\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9087\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8493\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6838\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4782\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3757\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.7355\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.8538\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3900\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.8081\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.0816\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.8422\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7802\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7625\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2578\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7055\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4520\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.1489\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3955\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7711\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 1.0084\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5452\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7343\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3124\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5478\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.1850\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2446\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5686\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2986\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.6908\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7200\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4667\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.7769\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3046\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4888\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5516\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.4006\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7718\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.1713\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4388\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.8079\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.1160\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4885\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8659\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4697\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.9401\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6901\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2487\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4532\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6515\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3532\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8042\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8755\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3280\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6118\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4820\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4812\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5549\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.0677\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6037\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5612\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3041\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6554\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3471\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2323\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3015\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 1.1377\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3463\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.7144\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4498\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2517\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8154\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.4381\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7120\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.2982\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5616\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3211\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3269\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.1014\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.6673\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.9057\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.9601\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8120\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6268\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2967\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8981\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.6266\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6377\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6525\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2790\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.4451\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2666\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.1821\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4155\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.8980\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 1.0000\n",
            "train/loss: 0.0529\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4295\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4947\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7813\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.5560\n",
            "val/accuracy_step: 87.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.7688\n",
            "val/loss: 0.5323\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 1.2616\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3816\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.0444\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3512\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.8400\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.8104\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5432\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6707\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.7287\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.7210\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7475\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5478\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 2.3188\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6854\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.6779\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7467\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.7151\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4509\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.8458\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3989\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.9541\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 1.0697\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4872\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.1074\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4476\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5233\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6154\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5028\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.3793\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5645\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2112\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.7201\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5091\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7591\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4040\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.7723\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.6500\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8963\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2872\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4344\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.8694\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1587\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2107\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4772\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4663\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4791\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4215\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3870\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.0374\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.5319\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6421\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6988\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8828\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.9189\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5631\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3008\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4093\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8020\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.0202\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4372\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7103\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3913\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3975\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5013\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7977\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.9263\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4244\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5443\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.9192\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2694\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.0044\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3884\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.6029\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.2416\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4833\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7742\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3962\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3362\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.8088\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6587\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.2208\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.1704\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.5957\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2676\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4618\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4064\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.9351\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.8125\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.3671\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1711\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2886\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5549\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6056\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3494\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6698\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5292\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6084\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3715\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.4344\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.2458\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.5658\n",
            "val/accuracy_step: 72.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.7344\n",
            "val/loss: 0.5394\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 1.3304\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.9312\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.1172\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6395\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8619\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6263\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3997\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9677\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6643\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7090\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.7273\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6298\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.2828\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4071\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5405\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3176\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.7640\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4947\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2603\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4792\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4705\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.0498\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.7343\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2179\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5193\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.2026\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.1747\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6046\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4175\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4445\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8546\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5414\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4623\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8954\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.4493\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.0981\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7262\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.8957\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 1.1530\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.5596\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2820\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.8735\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.9046\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5767\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6923\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4515\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4106\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6688\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4469\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5451\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.4427\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7559\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4720\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3552\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5777\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4992\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5221\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6757\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5461\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.5998\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6050\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6787\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8326\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5094\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6547\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5745\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2627\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.1825\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3303\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2638\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3995\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7991\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7343\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7348\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1972\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3584\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5944\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8895\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3559\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.1230\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4209\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.9792\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5183\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.2855\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5145\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.4097\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4076\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3596\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.8818\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2046\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3126\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5510\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.1866\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5466\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3043\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2405\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7560\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4157\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3047\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2307\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.8357\n",
            "val/accuracy_step: 60.00%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.8125\n",
            "val/loss: 0.3937\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 1.0561\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2748\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 1.2329\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.9078\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.8621\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3225\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 1.2223\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2282\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6945\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5054\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3510\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.2390\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 1.0000\n",
            "train/loss: 0.0234\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4873\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.9116\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 1.2325\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.7572\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3442\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3461\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.9362\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 1.1012\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9610\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7570\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7097\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3741\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.8077\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8806\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5946\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7720\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5274\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3492\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4482\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.0263\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7094\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4128\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 1.9085\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4581\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5602\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2698\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7011\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5722\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.8097\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.7968\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.7564\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4897\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9965\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.8974\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.2309\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.1784\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5751\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.2739\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5457\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.3910\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5179\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4394\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.7036\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 1.5254\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7533\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1210\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5446\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5176\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5931\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4083\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6070\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5155\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.2869\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5805\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6074\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7503\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2949\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9111\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5190\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.8402\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8034\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7204\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.5053\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6095\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5233\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5306\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.8706\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6215\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6302\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.6711\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5814\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3763\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9877\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.9213\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7423\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2580\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.2558\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3038\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4667\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6478\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.1866\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3448\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5674\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5691\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.4193\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.9547\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.2370\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.2747\n",
            "val/accuracy_step: 87.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.7312\n",
            "val/loss: 0.5377\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Acc over 5 instances: 0.76 +- 0.03\n",
            "Average Time over 5 instances: 7.370757222175598 +-0.3154293497063686\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WRN + PTMap + SOT"
      ],
      "metadata": {
        "id": "Y6XAMwMZ7SZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "times = []\n",
        "max_epochs = 100\n",
        "\n",
        "\n",
        "for seed in range(1, 5):\n",
        "  train_loader = get_dataloader(set_name='train'\n",
        "                              , num_episodes=1\n",
        "                              , train_way = 2\n",
        "                              , val_way = 2\n",
        "                              , num_shot = 5\n",
        "                              , num_query =20\n",
        "                              , data_path = dataset_path\n",
        "                              ,dataset = \"cifar\"\n",
        "                              , backbone = 'wrn'\n",
        "                              , constant = False\n",
        "                              ,augment = False)\n",
        "\n",
        "  val_loader = get_dataloader(set_name='val'\n",
        "                                , num_episodes=8\n",
        "                                , train_way = 2\n",
        "                                , val_way = 2\n",
        "                                , num_shot = 5\n",
        "                                , num_query =20\n",
        "                                , data_path = dataset_path\n",
        "                                , dataset = \"cifar\"\n",
        "                                , backbone = 'wrn'\n",
        "                                , constant = True\n",
        "                                ,augment = False)\n",
        "\n",
        "  model = get_model('wrn', 32)\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40)\n",
        "  sot = SOT()\n",
        "  method = get_method(\"pt_map\", sot, num_way, num_way, num_shot, num_query_train)\n",
        "\n",
        "  # few-shot labels\n",
        "  train_labels = get_fs_labels(method=\"pt_map\" ,num_way = num_way , num_query=num_query_train, num_shot=num_shot)\n",
        "  val_labels = get_fs_labels(method=\"pt_map\" ,num_way = num_way , num_query=num_query_test, num_shot=num_shot)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(max_epochs):\n",
        "    print(f\"Epoch {epoch}/{max_epochs}: \")\n",
        "    # train\n",
        "    train_one_epoch(model, train_loader, optimizer, method, criterion, train_labels, log_step=False , epoch=epoch, device = device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "  end_time = time.time()\n",
        "  times.append(end_time - start_time)\n",
        "\n",
        "  print('***********************************************************************************')\n",
        "  result = eval_one_epoch(model, val_loader, method, criterion, val_labels, epoch = epoch, device = device)\n",
        "  print('***********************************************************************************')\n",
        "  accs.append(result['val/accuracy'])\n",
        "\n",
        "times = np.array(times)\n",
        "accs = np.array(accs)\n",
        "print('Acc over 5 instances: %.2f +- %.2f'%(accs.mean(),accs.std()))\n",
        "print(f\"Average Time over 5 instances: {times.mean()} +-{times.std()}\")\n"
      ],
      "metadata": {
        "id": "bhnH4pQqTEHe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3b9dc50-4e7b-4cab-9e60-88966fecfa9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 2.4627\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7139\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7076\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.3500\n",
            "train/loss: 0.7573\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6360\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6763\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6783\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5141\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5916\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8799\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6995\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6682\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.3500\n",
            "train/loss: 0.6958\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7715\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6364\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6771\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6408\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5810\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5782\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.1522\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6736\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.3250\n",
            "train/loss: 1.4575\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7379\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5774\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6940\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6904\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6641\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4175\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6111\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6176\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.2480\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8475\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.7731\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6767\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6599\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7018\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6508\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6087\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6873\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6885\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4945\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.9261\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.9830\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.0054\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8071\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7948\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7018\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7113\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5468\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.5952\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5782\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.6931\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6812\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7602\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6636\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.6442\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.3000\n",
            "train/loss: 0.7020\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7148\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6021\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6839\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6267\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6589\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6971\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6354\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6936\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.6926\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6544\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7028\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6917\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6576\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7104\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7145\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6904\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6435\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8681\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6958\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5883\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.2750\n",
            "train/loss: 0.7143\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7022\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6804\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6600\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.6099\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6913\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6924\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6281\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6842\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5431\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6805\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6871\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5586\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6741\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5642\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6614\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.6973\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6934\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6592\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7431\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.3000\n",
            "train/loss: 0.8468\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.2750\n",
            "train/loss: 0.7956\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6967\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.5648\n",
            "val/accuracy_step: 75.00%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.6531\n",
            "val/loss: 0.6595\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 2.4684\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6648\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.9443\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.6879\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7889\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.9432\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6921\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.1692\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7285\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6791\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7534\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6622\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5447\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7613\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6904\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7539\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6084\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7037\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6669\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6600\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.3250\n",
            "train/loss: 0.8939\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6526\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7913\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7107\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6549\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5580\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.2750\n",
            "train/loss: 1.9002\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5971\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7014\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6495\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6604\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6054\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8848\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6399\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7133\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6848\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.6142\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7031\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6913\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.0755\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6581\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6343\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.6379\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.3500\n",
            "train/loss: 0.7810\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.7008\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6492\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6888\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6559\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6929\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6707\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6749\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6944\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.6145\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.6274\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6596\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.6923\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6896\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6293\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6894\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5866\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5650\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6983\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5958\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5899\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5306\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6909\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4951\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6756\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3156\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3754\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6606\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5606\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8920\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3473\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3361\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.1978\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7206\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3789\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7392\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3999\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6261\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.1944\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5749\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7427\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5484\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.8094\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5670\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6082\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6795\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.8658\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.3000\n",
            "train/loss: 0.7207\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6939\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6915\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6991\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5025\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3954\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5971\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4421\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6555\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3147\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.6004\n",
            "val/accuracy_step: 67.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.7688\n",
            "val/loss: 0.4873\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 1.0351\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5922\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5978\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6279\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7123\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6826\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7032\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7933\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7120\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5692\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.2674\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.7128\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6808\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6114\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.0784\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6092\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.3500\n",
            "train/loss: 1.0438\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6892\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 1.0192\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7054\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6821\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.3421\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6860\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6140\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.8005\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6861\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6887\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7082\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6632\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6822\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6674\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6649\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5649\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7088\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5854\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5553\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4485\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.7666\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3365\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6886\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6632\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7524\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7268\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7857\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6518\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7011\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.6950\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.6380\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6475\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6487\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6846\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.5974\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5921\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5983\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.6201\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7012\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6067\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6847\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5619\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6645\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6760\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7931\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6742\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5579\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5554\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.4662\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6585\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6881\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6703\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5502\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6928\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7912\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6677\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5766\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6235\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6528\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7124\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6897\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4731\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7236\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6362\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6744\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4822\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6918\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6977\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6385\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5156\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.4389\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2556\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7978\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6494\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7208\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7175\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7071\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5879\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6135\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.4936\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5319\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5479\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7458\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.5514\n",
            "val/accuracy_step: 70.00%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.6906\n",
            "val/loss: 0.5711\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 1.1983\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5111\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 1.1098\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5498\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6565\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7195\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6627\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.7973\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4830\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5817\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.0150\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6178\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5539\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5866\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.9261\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7069\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6905\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6907\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7077\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8069\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6639\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6871\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.0795\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.7071\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7431\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6980\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6615\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6591\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6850\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7015\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.7058\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7047\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6566\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5618\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9607\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5551\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6910\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3697\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7559\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6560\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6907\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6890\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5768\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7003\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7832\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7592\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4800\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5909\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7160\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5714\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4393\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7010\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7640\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.6821\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4102\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6385\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6112\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6632\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.6971\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6980\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4311\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6344\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5155\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6843\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3238\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4672\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3430\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5351\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4109\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2328\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7985\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4104\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5198\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8067\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6542\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6941\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 1.1794\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7140\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5014\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6804\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6815\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3981\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4995\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6534\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6843\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6820\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.7078\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5490\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.3500\n",
            "train/loss: 1.0487\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5648\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5667\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6910\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6888\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.6128\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6533\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6066\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6669\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.6218\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5021\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6200\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.4111\n",
            "val/accuracy_step: 92.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.6719\n",
            "val/loss: 0.6637\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Acc over 5 instances: 0.70 +- 0.04\n",
            "Average Time over 5 instances: 39.229222536087036 +-0.6292304048844034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "WRN + Proto + SOT"
      ],
      "metadata": {
        "id": "KwFZHMUqF7XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "times = []\n",
        "max_epochs = 100\n",
        "\n",
        "\n",
        "for seed in range(1, 5):\n",
        "  train_loader = get_dataloader(set_name='train'\n",
        "                              , num_episodes=1\n",
        "                              , train_way = 2\n",
        "                              , val_way = 2\n",
        "                              , num_shot = 5\n",
        "                              , num_query =20\n",
        "                              , data_path = dataset_path\n",
        "                              ,dataset = \"cifar\"\n",
        "                              , backbone = 'wrn'\n",
        "                              , constant = False\n",
        "                              ,augment = False)\n",
        "\n",
        "  val_loader = get_dataloader(set_name='val'\n",
        "                                , num_episodes=8\n",
        "                                , train_way = 2\n",
        "                                , val_way = 2\n",
        "                                , num_shot = 5\n",
        "                                , num_query =20\n",
        "                                , data_path = dataset_path\n",
        "                                , dataset = \"cifar\"\n",
        "                                , backbone = 'wrn'\n",
        "                                , constant = True\n",
        "                                ,augment = False)\n",
        "\n",
        "  model = get_model('wrn', 32)\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40)\n",
        "  sot = SOT()\n",
        "  method = get_method(\"proto_sot\", sot, num_way, num_way, num_shot, num_query_train)\n",
        "\n",
        "  # few-shot labels\n",
        "  train_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_train, num_shot=num_shot)\n",
        "  val_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_test, num_shot=num_shot)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  start_time = time.time()\n",
        "  for epoch in range(max_epochs):\n",
        "    print(f\"Epoch {epoch}/{max_epochs}: \")\n",
        "    # train\n",
        "    train_one_epoch(model, train_loader, optimizer, method, criterion, train_labels, log_step=False , epoch=epoch, device = device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "  end_time = time.time()\n",
        "  times.append(end_time - start_time)\n",
        "\n",
        "  print('***********************************************************************************')\n",
        "  result = eval_one_epoch(model, val_loader, method, criterion, val_labels, epoch = epoch, device = device)\n",
        "  print('***********************************************************************************')\n",
        "  accs.append(result['val/accuracy'])\n",
        "\n",
        "times = np.array(times)\n",
        "accs = np.array(accs)\n",
        "print('Acc over 5 instances: %.2f +- %.2f'%(accs.mean(),accs.std()))\n",
        "print(f\"Average Time over 5 instances: {times.mean()} +-{times.std()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf6Q1tzSEJqy",
        "outputId": "bc939334-acf2-4a1a-f905-eb5ec9c89d6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 1.3140\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 1.5551\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7137\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7062\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6101\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.0500\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.8130\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7692\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.9705\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5766\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.9755\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4745\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5697\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5598\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5308\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.8003\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3846\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4751\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 1.1477\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5885\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 1.1127\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6519\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7333\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6093\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6095\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6547\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5938\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5627\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.5812\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.9995\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2973\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7132\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.8695\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.8135\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 3.2411\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.7240\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.9737\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5956\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3738\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5729\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5196\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4987\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4123\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4768\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5812\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4522\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5069\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7992\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5528\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.0303\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6238\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5017\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4113\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4542\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.5868\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6581\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5577\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7189\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5149\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8456\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5340\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6273\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5488\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6469\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5255\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3099\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7057\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4978\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6559\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7552\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6519\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3213\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6399\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7197\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5340\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7914\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3845\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7104\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8674\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4533\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3496\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7492\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3253\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.2327\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6854\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4314\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7269\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3910\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6673\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6265\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6204\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6306\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4052\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6582\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3917\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6610\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5766\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.8095\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4076\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6605\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.8436\n",
            "val/accuracy_step: 47.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.7313\n",
            "val/loss: 0.5273\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6389\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.0727\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7158\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.8694\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.1705\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.4208\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 1.4785\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.9841\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5768\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.7514\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5097\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.7797\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6232\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9453\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7152\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7733\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.6034\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 2.1519\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7882\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6429\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 1.3745\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7807\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7505\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.8763\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 1.7893\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.7012\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7206\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6004\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.8767\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7046\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7778\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7420\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.7520\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5463\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6969\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.7442\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7375\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.9356\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5250\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.3500\n",
            "train/loss: 0.7234\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5315\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.7279\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7467\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8420\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3855\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.9821\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4280\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6498\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3998\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6344\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5176\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6264\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6410\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.4099\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6832\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.3250\n",
            "train/loss: 1.1135\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6804\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8888\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6466\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5964\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6329\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6816\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7825\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6337\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5195\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5325\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4491\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7316\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4702\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6636\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7646\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4935\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3987\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6269\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4909\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5207\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.4393\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7167\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5804\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5756\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6094\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4551\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4036\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7309\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2604\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2702\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6388\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6430\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4104\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7620\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.5629\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6689\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.6874\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7103\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6344\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7179\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5501\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.4000\n",
            "train/loss: 0.8921\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4568\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3632\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.3775\n",
            "val/accuracy_step: 82.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.6438\n",
            "val/loss: 0.6145\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.9293\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.8992\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6529\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6092\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7556\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7626\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3810\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.9079\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.4993\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.9510\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6425\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 2.1097\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6100\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.9943\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 1.1910\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5887\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.8778\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.8554\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6552\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7121\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6276\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.4029\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.8488\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4483\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6380\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7741\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7752\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3777\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6164\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8901\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 1.0034\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5189\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.9141\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.6133\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7807\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7761\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6704\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.9279\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5879\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7783\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6156\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6650\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.8402\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6930\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.1142\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7142\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7183\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6554\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6627\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6774\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5449\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6183\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6577\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6559\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6037\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4294\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7314\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5917\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6010\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5612\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6908\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8004\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4474\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7320\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4816\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7591\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.0006\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6115\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.7232\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.2778\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5151\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4448\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6040\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5709\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3648\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3476\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4617\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7682\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6535\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.5080\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.8069\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6945\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3599\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7426\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.7729\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7812\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3591\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3129\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2807\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5847\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3917\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5384\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6054\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4515\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4118\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.3977\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4082\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5927\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6908\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.4416\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.7168\n",
            "val/accuracy_step: 52.50%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.6469\n",
            "val/loss: 0.5959\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5512\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 1.9627\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.8878\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8073\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7143\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5019\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 1.1849\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4064\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6753\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7312\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 10/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5641\n",
            "train/epoch: 10.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 11/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7408\n",
            "train/epoch: 11.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 12/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 0.8463\n",
            "train/epoch: 12.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 13/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3588\n",
            "train/epoch: 13.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 14/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6718\n",
            "train/epoch: 14.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 15/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 1.0689\n",
            "train/epoch: 15.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 16/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6535\n",
            "train/epoch: 16.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 17/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7292\n",
            "train/epoch: 17.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 18/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.9518\n",
            "train/epoch: 18.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 19/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5152\n",
            "train/epoch: 19.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 20/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.3030\n",
            "train/epoch: 20.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 21/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6688\n",
            "train/epoch: 21.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 22/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6443\n",
            "train/epoch: 22.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 23/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.6178\n",
            "train/epoch: 23.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 24/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.6687\n",
            "train/epoch: 24.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 25/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6392\n",
            "train/epoch: 25.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 26/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.9950\n",
            "train/epoch: 26.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 27/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6168\n",
            "train/epoch: 27.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 28/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6277\n",
            "train/epoch: 28.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 29/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7339\n",
            "train/epoch: 29.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 30/100: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.3995\n",
            "train/epoch: 30.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 31/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.4340\n",
            "train/epoch: 31.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 32/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5023\n",
            "train/epoch: 32.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 33/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 1.0548\n",
            "train/epoch: 33.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 34/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.8331\n",
            "train/epoch: 34.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 35/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 1.8424\n",
            "train/epoch: 35.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 36/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.1394\n",
            "train/epoch: 36.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 37/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.7664\n",
            "train/epoch: 37.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 38/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 1.6272\n",
            "train/epoch: 38.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 39/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6219\n",
            "train/epoch: 39.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 40/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.5370\n",
            "train/epoch: 40.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 41/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4578\n",
            "train/epoch: 41.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 42/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.8119\n",
            "train/epoch: 42.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 43/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6950\n",
            "train/epoch: 43.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 44/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.9471\n",
            "train/epoch: 44.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 45/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.7616\n",
            "train/epoch: 45.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 46/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6819\n",
            "train/epoch: 46.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 47/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 1.6519\n",
            "train/epoch: 47.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 48/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6773\n",
            "train/epoch: 48.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 49/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3020\n",
            "train/epoch: 49.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 50/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.6232\n",
            "train/epoch: 50.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 51/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6287\n",
            "train/epoch: 51.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 52/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.7140\n",
            "train/epoch: 52.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 53/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7825\n",
            "train/epoch: 53.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 54/100: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.6052\n",
            "train/epoch: 54.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 55/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.8192\n",
            "train/epoch: 55.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 56/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 1.0232\n",
            "train/epoch: 56.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 57/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.0359\n",
            "train/epoch: 57.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 58/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4802\n",
            "train/epoch: 58.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 59/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.8293\n",
            "train/epoch: 59.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 60/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5536\n",
            "train/epoch: 60.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 61/100: \n",
            "train/accuracy: 0.5000\n",
            "train/loss: 0.7282\n",
            "train/epoch: 61.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 62/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.7699\n",
            "train/epoch: 62.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 63/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6132\n",
            "train/epoch: 63.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 64/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 1.2343\n",
            "train/epoch: 64.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 65/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7471\n",
            "train/epoch: 65.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 66/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.5951\n",
            "train/epoch: 66.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 67/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6637\n",
            "train/epoch: 67.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 68/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 1.0574\n",
            "train/epoch: 68.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 69/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.5841\n",
            "train/epoch: 69.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 70/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.8633\n",
            "train/epoch: 70.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 71/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4173\n",
            "train/epoch: 71.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 72/100: \n",
            "train/accuracy: 0.3750\n",
            "train/loss: 1.5220\n",
            "train/epoch: 72.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 73/100: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5442\n",
            "train/epoch: 73.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 74/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.5994\n",
            "train/epoch: 74.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 75/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6794\n",
            "train/epoch: 75.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 76/100: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4073\n",
            "train/epoch: 76.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 77/100: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.6285\n",
            "train/epoch: 77.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 78/100: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 1.3647\n",
            "train/epoch: 78.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 79/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.5938\n",
            "train/epoch: 79.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 80/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.6798\n",
            "train/epoch: 80.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 81/100: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.6524\n",
            "train/epoch: 81.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 82/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7128\n",
            "train/epoch: 82.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 83/100: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6907\n",
            "train/epoch: 83.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 84/100: \n",
            "train/accuracy: 0.6500\n",
            "train/loss: 0.6155\n",
            "train/epoch: 84.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 85/100: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4720\n",
            "train/epoch: 85.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 86/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7048\n",
            "train/epoch: 86.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 87/100: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.7063\n",
            "train/epoch: 87.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 88/100: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.6906\n",
            "train/epoch: 88.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 89/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4513\n",
            "train/epoch: 89.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 90/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7978\n",
            "train/epoch: 90.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 91/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.7335\n",
            "train/epoch: 91.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 92/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5469\n",
            "train/epoch: 92.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 93/100: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4551\n",
            "train/epoch: 93.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 94/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.4926\n",
            "train/epoch: 94.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 95/100: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.5649\n",
            "train/epoch: 95.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 96/100: \n",
            "train/accuracy: 0.6000\n",
            "train/loss: 0.7031\n",
            "train/epoch: 96.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 97/100: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.8663\n",
            "train/epoch: 97.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 98/100: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.4956\n",
            "train/epoch: 98.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 99/100: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7696\n",
            "train/epoch: 99.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.5645\n",
            "val/accuracy_step: 75.00%\n",
            "val/val_step: 784.0000\n",
            "val/accuracy: 0.6938\n",
            "val/loss: 0.5553\n",
            "val/epoch: 99.0000\n",
            "***********************************************************************************\n",
            "Acc over 5 instances: 0.68 +- 0.04\n",
            "Average Time over 5 instances: 28.115878760814667 +-0.4458623724396918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge 2"
      ],
      "metadata": {
        "id": "9KOYvtTWyXre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_weights(model: torch.nn.Module, pretrained_path: str):\n",
        "    \"\"\"\n",
        "    Load pretrained weights from given path.\n",
        "    \"\"\"\n",
        "    if not pretrained_path:\n",
        "        return model\n",
        "\n",
        "    print(f'Loading weights from {pretrained_path}')\n",
        "    state_dict = torch.load(pretrained_path)\n",
        "    sd_keys = list(state_dict.keys())\n",
        "    if 'state' in sd_keys:\n",
        "        state_dict = state_dict['state']\n",
        "        for k in list(state_dict.keys()):\n",
        "            if k.startswith('module.'):\n",
        "                state_dict[\"{}\".format(k[len('module.'):])] = state_dict[k]\n",
        "                del state_dict[k]\n",
        "\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "\n",
        "    elif 'params' in sd_keys:\n",
        "        state_dict = state_dict['params']\n",
        "        for k in list(state_dict.keys()):\n",
        "            if k.startswith('encoder.'):\n",
        "                state_dict[\"{}\".format(k[len('encoder.'):])] = state_dict[k]\n",
        "\n",
        "            del state_dict[k]\n",
        "\n",
        "        model.load_state_dict(state_dict, strict=True)\n",
        "    else:\n",
        "        model.load_state_dict(state_dict)\n",
        "\n",
        "    print(\"Weights loaded successfully \")\n",
        "    return model"
      ],
      "metadata": {
        "id": "bJXl7bK3yb23"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights_path = './feat-5-shot.pth'\n",
        "model = get_model('resnet12', 32)\n",
        "model.to(device)\n",
        "load_weights(model=model, pretrained_path=weights_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "et27U-DrydUQ",
        "outputId": "f9e0472d-904d-49d2-d29d-34ad4c796c92"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading weights from ./feat-5-shot.pth\n",
            "Weights loaded successfully \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNet(\n",
              "  (layer1): Sequential(\n",
              "    (0): ResBasicBlock(\n",
              "      (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): LeakyReLU(negative_slope=0.1)\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (DropBlock): DropBlock()\n",
              "    )\n",
              "  )\n",
              "  (layer2): Sequential(\n",
              "    (0): ResBasicBlock(\n",
              "      (conv1): Conv2d(64, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): LeakyReLU(negative_slope=0.1)\n",
              "      (conv2): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(64, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (DropBlock): DropBlock()\n",
              "    )\n",
              "  )\n",
              "  (layer3): Sequential(\n",
              "    (0): ResBasicBlock(\n",
              "      (conv1): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): LeakyReLU(negative_slope=0.1)\n",
              "      (conv2): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(160, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (DropBlock): DropBlock()\n",
              "    )\n",
              "  )\n",
              "  (layer4): Sequential(\n",
              "    (0): ResBasicBlock(\n",
              "      (conv1): Conv2d(320, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): LeakyReLU(negative_slope=0.1)\n",
              "      (conv2): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn2): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (conv3): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "      (bn3): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (downsample): Sequential(\n",
              "        (0): Conv2d(320, 640, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (1): BatchNorm2d(640, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (DropBlock): DropBlock()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.0, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accs = []\n",
        "max_epochs = 10\n",
        "\n",
        "\n",
        "for seed in range(1, 5):\n",
        "  train_loader = get_dataloader(set_name='train'\n",
        "                              , num_episodes=1\n",
        "                              , train_way = 2\n",
        "                              , val_way = 2\n",
        "                              , num_shot = 5\n",
        "                              , num_query =20\n",
        "                              , data_path = dataset_path\n",
        "                              ,dataset = \"cifar\"\n",
        "                              , backbone = 'resnet12'\n",
        "                              , constant = False\n",
        "                              ,augment = False)\n",
        "\n",
        "  val_loader = get_dataloader(set_name='val'\n",
        "                                , num_episodes=8\n",
        "                                , train_way = 2\n",
        "                                , val_way = 2\n",
        "                                , num_shot = 5\n",
        "                                , num_query =20\n",
        "                                , data_path = dataset_path\n",
        "                                , dataset = \"cifar\"\n",
        "                                , backbone = 'resnet12'\n",
        "                                , constant = True\n",
        "                                ,augment = False)\n",
        "\n",
        "  # model = get_model('resnet12', 32)\n",
        "  model.to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40)\n",
        "  sot = SOT()\n",
        "  method = get_method(\"proto_sot\", sot, num_way, num_way, num_shot, num_query_train)\n",
        "\n",
        "  # few-shot labels\n",
        "  train_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_train, num_shot=num_shot)\n",
        "  val_labels = get_fs_labels(method=\"proto_sot\" ,num_way = num_way , num_query=num_query_test, num_shot=num_shot)\n",
        "  criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "  for epoch in range(max_epochs):\n",
        "    print(f\"Epoch {epoch}/{max_epochs}: \")\n",
        "    # train\n",
        "    train_one_epoch(model, train_loader, optimizer, method, criterion, train_labels, log_step=False , epoch=epoch, device = device)\n",
        "    print('------------------------------------------------------------------------------------')\n",
        "    if scheduler is not None:\n",
        "        scheduler.step()\n",
        "\n",
        "  print('***********************************************************************************')\n",
        "  result = eval_one_epoch(model, val_loader, method, criterion, val_labels, epoch = epoch, device = device)\n",
        "  print('***********************************************************************************')\n",
        "  accs.append(result['val/accuracy'])\n",
        "\n",
        "accs = np.array(accs)\n",
        "print('Acc over 5 instances: %.2f +- %.2f'%(accs.mean(),accs.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V0VX4Dul080D",
        "outputId": "52de7753-0b87-4a3c-f7b6-b2c22580585e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/10: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4792\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/10: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.4844\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/10: \n",
            "train/accuracy: 0.4750\n",
            "train/loss: 0.7628\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/10: \n",
            "train/accuracy: 0.8000\n",
            "train/loss: 0.3110\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/10: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 0.6592\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/10: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2793\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/10: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 1.3050\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/10: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2545\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/10: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.4143\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/10: \n",
            "train/accuracy: 0.5500\n",
            "train/loss: 0.6818\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.5039\n",
            "val/accuracy_step: 80.00%\n",
            "val/val_step: 64.0000\n",
            "val/accuracy: 0.7750\n",
            "val/loss: 0.5772\n",
            "val/epoch: 9.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/10: \n",
            "train/accuracy: 0.6250\n",
            "train/loss: 0.7182\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/10: \n",
            "train/accuracy: 0.4500\n",
            "train/loss: 0.9247\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/10: \n",
            "train/accuracy: 0.5750\n",
            "train/loss: 1.1075\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/10: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1971\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/10: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 1.1869\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/10: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.2974\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/10: \n",
            "train/accuracy: 0.7750\n",
            "train/loss: 0.5113\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/10: \n",
            "train/accuracy: 0.7250\n",
            "train/loss: 0.4993\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/10: \n",
            "train/accuracy: 0.9500\n",
            "train/loss: 0.2030\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/10: \n",
            "train/accuracy: 0.5250\n",
            "train/loss: 0.7845\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.2172\n",
            "val/accuracy_step: 92.50%\n",
            "val/val_step: 64.0000\n",
            "val/accuracy: 0.7531\n",
            "val/loss: 0.5545\n",
            "val/epoch: 9.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/10: \n",
            "train/accuracy: 0.4250\n",
            "train/loss: 0.8509\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/10: \n",
            "train/accuracy: 0.7500\n",
            "train/loss: 0.5295\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/10: \n",
            "train/accuracy: 0.9750\n",
            "train/loss: 0.1847\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/10: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1997\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/10: \n",
            "train/accuracy: 0.8750\n",
            "train/loss: 0.5167\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/10: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2310\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/10: \n",
            "train/accuracy: 0.8500\n",
            "train/loss: 0.3334\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/10: \n",
            "train/accuracy: 0.6750\n",
            "train/loss: 0.7127\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/10: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.3030\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/10: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6808\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.2948\n",
            "val/accuracy_step: 90.00%\n",
            "val/val_step: 64.0000\n",
            "val/accuracy: 0.8719\n",
            "val/loss: 0.3393\n",
            "val/epoch: 9.0000\n",
            "***********************************************************************************\n",
            "Epoch 0/10: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.1477\n",
            "train/epoch: 0.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 1/10: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.3097\n",
            "train/epoch: 1.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 2/10: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2393\n",
            "train/epoch: 2.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 3/10: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4124\n",
            "train/epoch: 3.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 4/10: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2295\n",
            "train/epoch: 4.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 5/10: \n",
            "train/accuracy: 0.9250\n",
            "train/loss: 0.2179\n",
            "train/epoch: 5.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 6/10: \n",
            "train/accuracy: 0.7000\n",
            "train/loss: 0.6177\n",
            "train/epoch: 6.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 7/10: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.4357\n",
            "train/epoch: 7.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 8/10: \n",
            "train/accuracy: 0.8250\n",
            "train/loss: 0.3884\n",
            "train/epoch: 8.0000\n",
            "------------------------------------------------------------------------------------\n",
            "Epoch 9/10: \n",
            "train/accuracy: 0.9000\n",
            "train/loss: 0.2200\n",
            "train/epoch: 9.0000\n",
            "------------------------------------------------------------------------------------\n",
            "***********************************************************************************\n",
            "Batch 1/8: \n",
            "val/loss_step: 0.0502\n",
            "val/accuracy_step: 97.50%\n",
            "val/val_step: 64.0000\n",
            "val/accuracy: 0.8438\n",
            "val/loss: 0.4004\n",
            "val/epoch: 9.0000\n",
            "***********************************************************************************\n",
            "Acc over 5 instances: 0.81 +- 0.05\n"
          ]
        }
      ]
    }
  ]
}